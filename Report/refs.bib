@misc{baiONNXOpenNeural2019,
  title = {{{ONNX}}: {{Open}} Neural Network Exchange},
  author = {Bai, Junjie and Lu, Fang and Zhang, Ke and others},
  year = {2019},
  publisher = {GitHub}
}

@article{dagumOpenMPIndustryStandard1998,
  title = {{{OpenMP}}: An Industry Standard {{API}} for Shared-Memory Programming},
  shorttitle = {{{OpenMP}}},
  author = {Dagum, L. and Menon, R.},
  year = {1998},
  month = jan,
  journal = {IEEE Computational Science and Engineering},
  volume = {5},
  number = {1},
  pages = {46--55},
  issn = {1558-190X},
  doi = {10.1109/99.660313},
  urldate = {2024-10-16},
  abstract = {At its most elemental level, OpenMP is a set of compiler directives and callable runtime library routines that extend Fortran (and separately, C and C++ to express shared memory parallelism. It leaves the base language unspecified, and vendors can implement OpenMP in any Fortran compiler. Naturally, to support pointers and allocatables, Fortran 90 and Fortran 95 require the OpenMP implementation to include additional semantics over Fortran 77. OpenMP leverages many of the X3H5 concepts while extending them to support coarse grain parallelism. The standard also includes a callable runtime library with accompanying environment variables.},
  keywords = {ANSI standards,Coherence,Computer architecture,Hardware,Message passing,Parallel processing,Parallel programming,Power system modeling,Scalability,Software systems},
  file = {/Users/pantunes/Zotero/storage/EKBSIEKS/Dagum and Menon - 1998 - OpenMP an industry standard API for shared-memory programming.pdf;/Users/pantunes/Zotero/storage/QSNXY7EJ/660313.html}
}

@misc{developersONNXRuntime2021,
  title = {{{ONNX}} Runtime},
  author = {{developers}, ONNX Runtime},
  year = {2021}
}

@inproceedings{gabrielOpenMPIGoals2004,
  title = {Open {{MPI}}: {{Goals}}, {{Concept}}, and {{Design}} of a {{Next Generation MPI Implementation}}},
  shorttitle = {Open {{MPI}}},
  booktitle = {Recent {{Advances}} in {{Parallel Virtual Machine}} and {{Message Passing Interface}}},
  author = {Gabriel, Edgar and Fagg, Graham E. and Bosilca, George and Angskun, Thara and Dongarra, Jack J. and Squyres, Jeffrey M. and Sahay, Vishal and Kambadur, Prabhanjan and Barrett, Brian and Lumsdaine, Andrew and Castain, Ralph H. and Daniel, David J. and Graham, Richard L. and Woodall, Timothy S.},
  editor = {Kranzlm{\"u}ller, Dieter and Kacsuk, P{\'e}ter and Dongarra, Jack},
  year = {2004},
  pages = {97--104},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-30218-6_19},
  abstract = {A large number of MPI implementations are currently available, each of which emphasize different aspects of high-performance computing or are intended to solve a specific research problem. The result is a myriad of incompatible MPI implementations, all of which require separate installation, and the combination of which present significant logistical challenges for end users. Building upon prior research, and influenced by experience gained from the code bases of the LAM/MPI, LA-MPI, and FT-MPI projects, Open MPI is an all-new, production-quality MPI-2 implementation that is fundamentally centered around component concepts. Open MPI provides a unique combination of novel features previously unavailable in an open-source, production-quality implementation of MPI. Its component architecture provides both a stable platform for third-party research as well as enabling the run-time composition of independent software add-ons. This paper presents a high-level overview the goals, design, and implementation of Open MPI.},
  isbn = {978-3-540-30218-6},
  langid = {english},
  keywords = {Collective Operation,Component Architecture,Component Framework,Message Passing Interface,Reference Count},
  file = {/Users/pantunes/Zotero/storage/RXZCR6LR/Gabriel et al. - 2004 - Open MPI Goals, Concept, and Design of a Next Generation MPI Implementation.pdf}
}

@misc{kraiskilONNX2C2024,
  title = {{{ONNX2C}}},
  author = {{kraiskil}},
  year = {2024},
  month = oct,
  urldate = {2024-10-16},
  abstract = {Open Neural Network Exchange to C compiler.},
  keywords = {edge-computing,machine-learning,microcontroller,neural-network,onnx}
}

@article{lecunMNISTHandwrittenDigit2010,
  title = {{{MNIST}} Handwritten Digit Database},
  author = {LeCun, Yann and Cortes, Corinna and Burges, {\relax CJ}},
  year = {2010},
  journal = {ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},
  volume = {2}
}

@misc{lutzroederNetron2024,
  title = {Netron},
  author = {{Lutz Roeder}},
  year = {2024},
  urldate = {2024-10-11},
  copyright = {MIT License},
  file = {/Users/pantunes/Zotero/storage/U379JQNJ/netron.html}
}

@misc{martinabadiTensorFlowLargescaleMachine2015,
  title = {{{TensorFlow}}: {{Large-scale}} Machine Learning on Heterogeneous Systems},
  author = {{Mart{\'i}n Abadi} and {Ashish Agarwal} and {Paul Barham} and {Eugene Brevdo} and {Zhifeng Chen} and {Craig Citro} and {Greg S. Corrado} and {Andy Davis} and {Jeffrey Dean} and {Matthieu Devin} and {Sanjay Ghemawat} and {Ian Goodfellow} and {Andrew Harp} and {Geoffrey Irving} and {Michael Isard} and Jia, Yangqing and {Rafal Jozefowicz} and {Lukasz Kaiser} and {Manjunath Kudlur} and {Josh Levenberg} and {Dandelion Man{\'e}} and {Rajat Monga} and {Sherry Moore} and {Derek Murray} and {Chris Olah} and {Mike Schuster} and {Jonathon Shlens} and {Benoit Steiner} and {Ilya Sutskever} and {Kunal Talwar} and {Paul Tucker} and {Vincent Vanhoucke} and {Vijay Vasudevan} and {Fernanda Vi{\'e}gas} and {Oriol Vinyals} and {Pete Warden} and {Martin Wattenberg} and {Martin Wicke} and {Yuan Yu} and {Xiaoqiang Zheng}},
  year = {2015}
}

@article{nethercoteValgrindProgramSupervision2003,
  title = {Valgrind: {{A Program Supervision Framework}}},
  shorttitle = {Valgrind},
  author = {Nethercote, Nicholas and Seward, Julian},
  year = {2003},
  month = oct,
  journal = {Electronic Notes in Theoretical Computer Science},
  series = {{{RV}} '2003, {{Run-time Verification}} ({{Satellite Workshop}} of {{CAV}} '03)},
  volume = {89},
  number = {2},
  pages = {44--66},
  issn = {1571-0661},
  doi = {10.1016/S1571-0661(04)81042-9},
  urldate = {2024-10-01},
  abstract = {Valgrind is a programmable framework for creating program supervision tools such as bug detectors and profilers. It executes supervised programs using dynamic binary translation, giving it total control over their every part without requiring source code, and without the need for recompilation or relinking prior to execution. New supervision tools can be easily created by writing skins that plug into Valgrind's core. As an example, we describe one skin that performs Purify-style memory checks for C and C++ programs.},
  file = {/Users/pantunes/Zotero/storage/IPB65LRV/S1571066104810429.html}
}

@misc{onnxOnnxmlir2024,
  title = {Onnx-Mlir},
  author = {{onnx}},
  year = {2024},
  month = oct,
  urldate = {2024-10-16},
  abstract = {Representation and Reference Lowering of ONNX Models in MLIR Compiler Infrastructure},
  copyright = {Apache-2.0},
  howpublished = {Open Neural Network Exchange}
}

@misc{openvinotoolkitOpenvino2024,
  title = {Openvino},
  author = {{openvinotoolkit}},
  year = {2024},
  month = oct,
  urldate = {2024-10-16},
  abstract = {OpenVINO™ is an open-source toolkit for optimizing and deploying AI inference},
  copyright = {Apache-2.0},
  howpublished = {OpenVINO™ Toolkit},
  keywords = {ai,computer-vision,deep-learning,deploy-ai,diffusion-models,generative-ai,good-first-issue,inference,llm-inference,natural-language-processing,nlp,openvino,optimize-ai,performance-boost,recommendation-system,speech-recognition,stable-diffusion,transformers,yolo}
}

@incollection{paszkePyTorchImperativeStyle2019,
  title = {{{PyTorch}}: An Imperative Style, High-Performance Deep Learning Library},
  shorttitle = {{{PyTorch}}},
  booktitle = {Proceedings of the 33rd {{International Conference}} on {{Neural Information Processing Systems}}},
  author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and K{\"o}pf, Andreas and Yang, Edward and DeVito, Zach and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  year = {2019},
  month = dec,
  pages = {8026--8037},
  publisher = {Curran Associates Inc.},
  address = {Red Hook, NY, USA},
  urldate = {2024-10-16},
  abstract = {Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it provides an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs.In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several common benchmarks.},
  articleno = {721},
  file = {/Users/pantunes/Zotero/storage/CTADCRLA/Paszke et al. - 2019 - PyTorch an imperative style, high-performance deep learning library.pdf}
}

@misc{revueltaCONNXr2024,
  title = {{{cONNXr}}},
  author = {Revuelta, Alvaro},
  year = {2024},
  month = oct,
  urldate = {2024-10-16},
  abstract = {Pure C ONNX runtime with zero dependancies for embedded devices},
  copyright = {MIT},
  keywords = {ai-framework,embedded-devices,machine-learning,onnx,protocol-buffers}
}

@inproceedings{weidendorferSequentialPerformanceAnalysis2008,
  title = {Sequential {{Performance Analysis}} with {{Callgrind}} and {{KCachegrind}}},
  booktitle = {Tools for {{High Performance Computing}}},
  author = {Weidendorfer, Josef},
  editor = {Resch, Michael and Keller, Rainer and Himmler, Valentin and Krammer, Bettina and Schulz, Alexander},
  year = {2008},
  pages = {93--113},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-68564-7_7},
  abstract = {This chapter presents the suite of tools Callgrind and KCachegrind. The first is an execution driven cache simulator, which outputs profile information on cache events, as well as the dynamic call graph of the execution, attributed with call counts and inclusive costs. KCachegrind is a visualization tool tailored at browsing the results gathered by Callgrind. After some introduction to sequential performance analysis and related tools, the tool suite is presented, followed by typical use cases. Finally, future developments are discussed.},
  isbn = {978-3-540-68564-7},
  langid = {english},
  keywords = {68-06,68N18,68Q60,68Q85,68U99,94A99},
  file = {/Users/pantunes/Zotero/storage/WY4V93AT/Weidendorfer - 2008 - Sequential Performance Analysis with Callgrind and KCachegrind.pdf}
}

@misc{xbootLibonnxLightweightPortable2024,
  title = {Libonnx: {{A}} Lightweight, Portable Pure {{C99}} Onnx Inference Engine for Embedded Devices with Hardware Acceleration Support.},
  author = {{xboot}},
  year = {2024},
  urldate = {2024-10-16},
  file = {/Users/pantunes/Zotero/storage/6NPRCBG8/libonnx.html}
}
